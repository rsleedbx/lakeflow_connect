{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75ea095d-e3dd-4c62-9aaf-76c096e56433",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "parameters:\n",
    "- action_name\n",
    "- connection_name\n",
    "- gateway_pipeline_id\n",
    "- ingestion_pipeline_id\n",
    "- job_id\n",
    "- stage_catalog\n",
    "- stage_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default widget / parameters values\n",
    "action_name=dbutils.widgets.text(\"action_name\",\"\")\n",
    "\n",
    "connection_name=dbutils.widgets.text(\"connection_name\",\"\")\n",
    "gateway_pipeline_name=dbutils.widgets.text('gateway_pipeline_name',\"\")\n",
    "gateway_pipeline_id=dbutils.widgets.text('gateway_pipeline_id',\"\")\n",
    "ingestion_pipeline_name=dbutils.widgets.text('ingestion_pipeline_name',\"\")\n",
    "ingestion_pipeline_id=dbutils.widgets.text('ingestion_pipeline_id',\"\")\n",
    "job_name=dbutils.widgets.text('job_name',\"\")\n",
    "job_id=dbutils.widgets.text('job_id',\"\")\n",
    "\n",
    "elog_catalog=dbutils.widgets.text('elog_catalog',\"\")\n",
    "elog_schema=dbutils.widgets.text('elog_schema',\"\")\n",
    "stage_catalog=dbutils.widgets.text('stage_catalog',\"\")\n",
    "stage_schema=dbutils.widgets.text('stage_schema',\"\")\n",
    "target_catalog=dbutils.widgets.text('target_catalog',\"\")\n",
    "target_schema=dbutils.widgets.text('target_schema',\"\")\n",
    "\n",
    "connection_created=dbutils.widgets.text('connection_created',\"\")\n",
    "stage_created=dbutils.widgets.text('stage_created',\"\")\n",
    "target_created=dbutils.widgets.text('target_created',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5fd3441-2387-4b12-a32f-6f8b37244cca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "w = WorkspaceClient()\n",
    "action_name=dbutils.widgets.get(\"action_name\")\n",
    "connection_name=dbutils.widgets.get(\"connection_name\")\n",
    "gateway_pipeline_name=dbutils.widgets.get('gateway_pipeline_name')\n",
    "gateway_pipeline_id=dbutils.widgets.get('gateway_pipeline_id')\n",
    "ingestion_pipeline_name=dbutils.widgets.get('ingestion_pipeline_name')\n",
    "ingestion_pipeline_id=dbutils.widgets.get('ingestion_pipeline_id')\n",
    "job_name=dbutils.widgets.get('job_name')\n",
    "job_id=dbutils.widgets.get('job_id')\n",
    "\n",
    "elog_catalog=dbutils.widgets.get('elog_catalog')\n",
    "elog_schema=dbutils.widgets.get('elog_schema')\n",
    "stage_catalog=dbutils.widgets.get('stage_catalog')\n",
    "stage_schema=dbutils.widgets.get('stage_schema')\n",
    "target_catalog=dbutils.widgets.get('target_catalog')\n",
    "target_schema=dbutils.widgets.get('target_schema')\n",
    "\n",
    "connection_created=dbutils.widgets.get('connection_created')\n",
    "stage_created=dbutils.widgets.get('stage_created')\n",
    "target_created=dbutils.widgets.get('target_created')\n",
    "\n",
    "gateway_elog_table_name=f\"{elog_catalog}.{elog_schema}.gateway_elog_{gateway_pipeline_id.replace('-', '_')}\"\n",
    "ingestion_elog_table_name=f\"{elog_catalog}.{elog_schema}.ingestion_elog_{ingestion_pipeline_id.replace('-', '_')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cc3f35d-40b0-4b1a-b903-3863e158c1c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if action_name==\"stop\" or action_name==\"delete\":\n",
    "    try:\n",
    "        w.pipelines.stop(pipeline_id=gateway_pipeline_id)\n",
    "        print(f\"pipelines stop {gateway_pipeline_id=}\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8fabda9-34be-4074-a550-0fe6fd0058c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if action_name==\"stop\" or action_name==\"delete\":\n",
    "    try:\n",
    "        w.pipelines.stop(pipeline_id=ingestion_pipeline_id)\n",
    "        print(f\"pipelines stop {ingestion_pipeline_id=}\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f4afb94-996c-4453-9942-4d1e4505490b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if action_name==\"stop\" or action_name==\"delete\":\n",
    "    try:\n",
    "        spark.sql(f\"\"\"\n",
    "        create table if not exists identifier('{gateway_elog_table_name}') select * from event_log('{gateway_pipeline_id}') limit 0;\n",
    "        \"\"\")\n",
    "        spark.sql(f\"\"\"\n",
    "        insert into identifier('{gateway_elog_table_name}') select * from event_log('{gateway_pipeline_id}');\n",
    "        \"\"\")\n",
    "        print(f\"insert into identifier('{gateway_elog_table_name=}') select * from event_log('{gateway_pipeline_id=}')\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "653b0d2a-8997-413c-b66d-1756446bee1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if action_name==\"stop\" or action_name==\"delete\":\n",
    "    try:\n",
    "        spark.sql(f\"\"\"\n",
    "        create table if not exists identifier('{ingestion_elog_table_name}') select * from event_log('{ingestion_pipeline_id}') limit 0;\n",
    "        \"\"\")\n",
    "        spark.sql(f\"\"\"\n",
    "        insert into identifier('{ingestion_elog_table_name}') select * from event_log('{ingestion_pipeline_id}');\n",
    "        \"\"\")\n",
    "        print(f\"insert into identifier('{ingestion_elog_table_name=}') select * from event_log('{ingestion_pipeline_id=}')\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d11c9f58-7cdb-41e8-ae58-e3952a053169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import logging\n",
    "import inspect\n",
    "import time\n",
    "\n",
    "def loadGatewayMetricsTable(\n",
    "  spark:SparkSession,\n",
    "  staging_catalog_name:str, \n",
    "  staging_schema_name:str, \n",
    "  gateway_pipeline_id:str=\"\",\n",
    "  elog_catalog_name:str=\"\", \n",
    "  elog_schema_name:str=\"\", \n",
    "  timeout=30,\n",
    "  max_wait=10,\n",
    "  ) -> str:\n",
    "\n",
    "  if not elog_catalog_name: elog_catalog_name=staging_catalog_name\n",
    "  if not elog_schema_name: elog_schema_name=staging_schema_name\n",
    "\n",
    "  rootPath = f\"/Volumes/{staging_catalog_name}/{staging_schema_name}/__databricks_ingestion_gateway_staging_data-{gateway_pipeline_id}/{gateway_pipeline_id}/\"\n",
    "  loadPath = f\"{rootPath}/telemetry/\"\n",
    "  checkpointPath = f\"{rootPath}/monitoring/checkpoint/{gateway_pipeline_id}/\"\n",
    "  schemaLocation = f\"{rootPath}/monitoring/schema/{gateway_pipeline_id}/\"\n",
    "  table_name = f\"gateway_metrics_table_{gateway_pipeline_id}\".replace(\"-\",\"_\")\n",
    "  outputTableName = f\"{elog_catalog_name}.{elog_schema_name}.{table_name}\"\n",
    "  outputTableName = outputTableName.replace(\"-\", \"_\")\n",
    "\n",
    "  outputTableName_exists = spark.catalog.tableExists(outputTableName)  \n",
    "  if not outputTableName_exists:\n",
    "    print(f\"{outputTableName}\")\n",
    "\n",
    "  try:\n",
    "    autoloaderStream = (\n",
    "        spark.readStream.format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.includeExistingFiles\", True)\n",
    "        .option(\"cloudFiles.format\", \"json\")\n",
    "        .option(\"cloudFiles.inferColumnTypes\", True)\n",
    "        .option(\"cloudFiles.schemaLocation\", schemaLocation)\n",
    "        .option(\"cloudFiles.schemaHints\", \"\"\"\n",
    "            catalog_name string, \n",
    "            dlt_event_type string, \n",
    "            event_subtype string, \n",
    "            event_timestamp_seconds long, \n",
    "            event_type string, \n",
    "            flow_name string, \n",
    "            flow_status string, \n",
    "            is_failed boolean, \n",
    "            phase string, \n",
    "            pipeline_id string, \n",
    "            replication_id string, \n",
    "            schema_name string, \n",
    "            source string, \n",
    "            statistics struct<deleteCount: long, duration_ms: long, insertCount: long, last_operation_timestamp: long, outputCount: long, updateCount: long, upsertCount: long, rowRangeStart: string, rowRangeEnd: string, startTimestamp: string, ddl map<string, string>, endTimestamp: string >, \n",
    "            table struct<catalog_name: string, schema_name: string, table_name: string>, \n",
    "            table_name string, \n",
    "            update_state string, \n",
    "            resources struct<name: string, type: string, committed_memory: long, max_memory: long, used_memory: long, collection_count: long, total_memory: long, free_memory: long, collection_time: long>,\n",
    "            error_detail string,\n",
    "            exit_code string,\n",
    "            stacktrace string,\n",
    "            exception_name string,\n",
    "            exception string\n",
    "        \"\"\")\n",
    "      .option(\"cloudFiles.schemaEvolutionMode\", \"addNewColumns\")\n",
    "      .option(\"mergeSchema\", True)\n",
    "      .load(f\"{loadPath}\")\n",
    "      .writeStream\n",
    "      .option(\"mergeSchema\", True)\n",
    "      .option(\"checkpointLocation\", checkpointPath)\n",
    "      .trigger(availableNow=True)\n",
    "      .toTable(outputTableName)\n",
    "      )\n",
    "\n",
    "    # wait for this to finish\n",
    "    # not needed in jobs https://docs.databricks.com/en/structured-streaming/production.html\n",
    "    # autoloaderStream.awaitTermination()\n",
    "  except Exception as ex:\n",
    "    print(ex)\n",
    "    return(\"\")\n",
    "\n",
    "  # \n",
    "  waited = 0\n",
    "  while not outputTableName_exists:\n",
    "    print(f\"{inspect.stack()[1][3]}: wait table creation: {waited}/{max_wait}. sleeping {timeout}\")\n",
    "    waited += 1\n",
    "    time.sleep(timeout)\n",
    "    outputTableName_exists = spark.catalog.tableExists(outputTableName)  \n",
    "\n",
    "  if outputTableName_exists:  \n",
    "    return(table_name)\n",
    "  else:\n",
    "    return(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8785c84-d87a-46ec-816d-11fb5a964710",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if 1:\n",
    "  try:\n",
    "    print(\n",
    "      loadGatewayMetricsTable(\n",
    "      spark=spark,\n",
    "      staging_catalog_name=stage_catalog,\n",
    "      staging_schema_name=stage_schema,\n",
    "      gateway_pipeline_id=gateway_pipeline_id,\n",
    "      elog_catalog_name=elog_catalog,\n",
    "      elog_schema_name=elog_schema\n",
    "      )\n",
    "    )\n",
    "  except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40e1e9cc-635d-4815-8a27-3c49920eda74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "if action_name==\"delete\":\n",
    "    try:\n",
    "        w.jobs.delete(job_id=job_id)\n",
    "        print(f\"jobs delete {job_id=}\")        \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef89b2d7-6207-4da6-b50d-eaf3ff2fc6a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "if action_name==\"delete\":\n",
    "    try:\n",
    "        w.pipelines.delete(pipeline_id=ingestion_pipeline_id)\n",
    "        print(f\"pipelines delete {ingestion_pipeline_id=}\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "940f1b60-bb1f-4560-9738-61e4071781e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "if action_name==\"delete\":\n",
    "    try:\n",
    "        w.pipelines.delete(pipeline_id=gateway_pipeline_id)\n",
    "        print(f\"pipelines delete {gateway_pipeline_id=}\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "593a4b16-28ff-4f01-9992-9a7e97ba433b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "if action_name==\"delete\" and connection_created:\n",
    "    try:\n",
    "        w.connections.delete(name=connection_name)\n",
    "        print(f\"connections delete {connection_name=}\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "if action_name==\"delete\" and stage_created:\n",
    "    try:\n",
    "        spark.sql(f\"DROP SCHEMA {stage_catalog}.{stage_schema} CASCADE\")\n",
    "        print(f\"DROP SCHEMA {stage_catalog=}.{stage_schema=} CASCADE\")    \n",
    "    except Exception as e:\n",
    "        print(e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "if action_name==\"delete\" and target_created:\n",
    "    try:\n",
    "        spark.sql(f\"DROP SCHEMA {target_catalog}.{target_schema} CASCADE\")\n",
    "        print(f\"DROP SCHEMA {target_catalog}.{target_schema} CASCADE\")    \n",
    "    except Exception as e:\n",
    "        print(e)    "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "copy_event_log.ipynb",
   "widgets": {
    "action_name": {
     "currentValue": "delete",
     "nuid": "6f8e8b6b-0e4f-49c0-b6c1-ef43ea953618",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "action_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "",
      "name": "action_name",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "connection_name": {
     "currentValue": "",
     "nuid": "339002e0-5841-4a1b-86d8-4eb4cb4bf9e8",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "connection_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "",
      "name": "connection_name",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "gateway_pipeline_id": {
     "currentValue": "",
     "nuid": "ad89c598-3ac8-411a-9806-fe14babd0ea4",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "gateway_pipeline_id",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "",
      "name": "gateway_pipeline_id",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "ingestion_pipeline_id": {
     "currentValue": "",
     "nuid": "63ea1ecb-4bf8-46d9-9f5c-9fed9180c96b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "ingestion_pipeline_id",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "",
      "name": "ingestion_pipeline_id",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "job_id": {
     "currentValue": "",
     "nuid": "81c616df-620b-436c-9b6b-08ff34f55414",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "job_id",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "",
      "name": "job_id",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "stage_catalog": {
     "currentValue": "",
     "nuid": "df0a33bb-921a-4f85-8dc5-0cbb1b384247",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "stage_catalog",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "",
      "name": "stage_catalog",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "stage_schema": {
     "currentValue": "",
     "nuid": "25b096b6-8e2a-4744-b2ca-fe313363fe30",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "stage_schema",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "",
      "name": "stage_schema",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
